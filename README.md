## üöÄ Installation Rapide

1. **Installer les d√©pendances** : `pip install -r requirements.txt`
2. **Installer / Lister / Changer / Supprimer un LLM** : `python models/llm/llm_model_installer.py`
3. **Lancer l'application** : `streamlit run app.py`
4. **Nettoyer les caches** : `python clear_cache.py`



# üöÄ VEV RAG - Agent RAG Haute Performance 100% Local

<div align="center">

![VEV Agent](VEV%20Agent.png)

**Agent RAG (Retrieval-Augmented Generation) haute performance fonctionnant 100% en local sur CPU.**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![CPU Only](https://img.shields.io/badge/CPU-Only-orange.svg)]()
[![Local First](https://img.shields.io/badge/Local-First-purple.svg)]()

</div>

---

## üìã Table des Mati√®res

- [√Ä Propos](#-√†-propos)
- [Fonctionnalit√©s](#-fonctionnalit√©s)
- [Architecture](#-architecture)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [Technologies](#-technologies)
- [Contribution](#-contribution)

---

## üéØ √Ä Propos

**VEV RAG** est un syst√®me de recherche documentaire intelligent qui combine :
- üîç **Recherche s√©mantique** avanc√©e avec embeddings
- ü§ñ **G√©n√©ration de r√©ponses** via LLM local (Qwen3-4B)
- üìö **Ingestion multi-format** (PDF, DOCX, TXT, Web)
- üíæ **Base vectorielle hybride** (LanceDB)
- ‚ö° **Performance CPU optimis√©e** (ONNX, GGUF)

Le projet fonctionne **enti√®rement en local**, sans d√©pendance cloud, garantissant confidentialit√© et autonomie.

---

## ‚ú® Fonctionnalit√©s

### üî• Principales

- ‚úÖ **Ingestion intelligente** : Support PDF, Word, TXT et pages web
- ‚úÖ **Chunking s√©mantique** : D√©coupage intelligent par sens (2023)
- ‚úÖ **Embeddings rapides** : BGE-M3 via FastEmbed (ONNX)
- ‚úÖ **Recherche hybride** : Vectorielle + BM25/FTS
- ‚úÖ **Reranking** : MXBai Rerank v2 pour affiner les r√©sultats
- ‚úÖ **Cache s√©mantique** : GPTCache pour acc√©l√©rer les requ√™tes
- ‚úÖ **LLM local** : Qwen3-4B quantifi√© (GGUF Q4_K_M)
- ‚úÖ **Interface Streamlit** : Chat interactif avec upload de documents
- ‚úÖ **√âvaluation RAGAS** : M√©triques de qualit√© automatiques

### üõ°Ô∏è S√©curit√© & Performance

- üîí **100% Local** : Aucune donn√©e ne quitte votre machine
- ‚ö° **CPU Optimis√©** : Fonctionne sans GPU
- üìä **√âvaluation continue** : Scores de fid√©lit√© et pertinence
- üßπ **Nettoyage avanc√©** : ftfy, clean-text, Spacy

---

## üèóÔ∏è Architecture

```mermaid
graph TB
    A[Documents PDF/DOCX/TXT/Web] --> B[Ingestion & Nettoyage]
    B --> C[Chunking S√©mantique]
    C --> D[Embeddings BGE-M3]
    D --> E[LanceDB Vectorielle]
    F[Question Utilisateur] --> G[Query Expansion HyDE]
    G --> H[Recherche Hybride]
    E --> H
    H --> I[Reranking MXBai]
    I --> J[LLM Qwen3-4B]
    J --> K[R√©ponse G√©n√©r√©e]
    L[GPTCache] -.-> H
```

### Pipeline Complet

1. **Ingestion** : Docling (IBM 2024) convertit les documents en Markdown
2. **Nettoyage** : ftfy + clean-text + Spacy normalisent le texte
3. **Chunking** : Segmentation s√©mantique intelligente
4. **Vectorisation** : FastEmbed + BGE-M3 (ONNX, CPU-optimis√©)
5. **Stockage** : LanceDB (hybride vectoriel + BM25)
6. **Recherche** : Query expansion (HyDE) + recherche hybride
7. **Reranking** : MXBai Rerank v2 affine le top-5
8. **G√©n√©ration** : Qwen3-4B (GGUF Q4) g√©n√®re la r√©ponse
9. **√âvaluation** : RAGAS mesure la qualit√©

---

## üì¶ Installation

### Pr√©requis

- Python 3.10 ou sup√©rieur
- 8 GB RAM minimum (16 GB recommand√©)
- CPU moderne (pas de GPU requis)

### Installation Rapide

```bash
# Cloner le d√©p√¥t
git clone https://github.com/user257814938/VEV_RAG.git
cd VEV_RAG

# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installer les d√©pendances
pip install -r requirements.txt

# T√©l√©charger les mod√®les
python src/scripts/download_reranker.py
```

### Configuration

Cr√©ez un fichier `.env` √† la racine (optionnel) :

```env
# Chemins personnalis√©s (optionnel)
DATA_DIR=./data
MODELS_DIR=./models
```

---

## üöÄ Utilisation

### Interface Streamlit (Recommand√©)

```bash
streamlit run app.py
```

Ouvrez votre navigateur √† `http://localhost:8501`

### Utilisation Programmatique

```python
from main import VEVRAGAgent

# Initialiser l'agent
agent = VEVRAGAgent()

# Ing√©rer des documents
agent.ingest_documents(["document.pdf", "article.docx"])

# Poser une question
response = agent.query("Quelle est la d√©finition de l'IA ?")
print(response)
```

### Tests

```bash
# Lancer les tests
pytest tests/

# Test d'ingestion
python tests/test_ingestion.py

# Test de recherche
python tests/test_retrieval.py
```

---

## üìÅ Structure du Projet

```
VEV_RAG/
‚îú‚îÄ‚îÄ üìÑ app.py                    # Interface Streamlit
‚îú‚îÄ‚îÄ üìÑ main.py                   # Orchestration principale (VEVRAGAgent)
‚îú‚îÄ‚îÄ üìÑ requirements.txt          # D√©pendances Python
‚îú‚îÄ‚îÄ üìÇ src/
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py           # Configuration & variables d'environnement
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py          # Structures de donn√©es (Pydantic)
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader_doc.py       # Chargement PDF/DOCX (Docling)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader_web.py       # Extraction web (Trafilatura)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cleaner.py          # Nettoyage texte (ftfy, Spacy)
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ indexing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunker.py          # Chunking s√©mantique
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedder.py         # Embeddings (FastEmbed + BGE-M3)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_store.py     # Base vectorielle (LanceDB)
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ retrieval/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache.py            # Cache s√©mantique (GPTCache)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ query_expansion.py  # Am√©lioration requ√™tes (HyDE)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reranker.py         # Reranking (MXBai)
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ generation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_engine.py       # Moteur LLM (Qwen3-4B GGUF)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ system_prompts.py   # Prompts syst√®me
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ evaluation/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ragas_eval.py       # √âvaluation qualit√© (RAGAS)
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ download_reranker.py # T√©l√©chargement mod√®les
‚îÇ       ‚îî‚îÄ‚îÄ verify_paths.py      # V√©rification structure
‚îú‚îÄ‚îÄ üìÇ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Documents bruts
‚îÇ   ‚îú‚îÄ‚îÄ processed/              # Documents trait√©s
‚îÇ   ‚îî‚îÄ‚îÄ lancedb/                # Base vectorielle
‚îú‚îÄ‚îÄ üìÇ models/
‚îÇ   ‚îú‚îÄ‚îÄ llm/                    # Mod√®les LLM (GGUF)
‚îÇ   ‚îî‚îÄ‚îÄ embeddings/             # Mod√®les embeddings
‚îî‚îÄ‚îÄ üìÇ tests/
    ‚îú‚îÄ‚îÄ test_ingestion.py       # Tests ingestion
    ‚îî‚îÄ‚îÄ test_retrieval.py       # Tests recherche
```

---

## üîß Technologies

### Stack Compl√®te

| Composant | Technologie | Ann√©e | R√¥le |
|-----------|-------------|-------|------|
| **Ingestion** | Docling (IBM) | 2024 | Conversion PDF/DOCX ‚Üí Markdown |
| **Web Scraping** | Trafilatura | 2019 | Extraction contenu web |
| **Nettoyage** | ftfy, clean-text, Spacy | 2012-2019 | Normalisation texte |
| **Chunking** | Semantic Chunking | 2023 | Segmentation intelligente |
| **Embeddings** | FastEmbed + BGE-M3 | 2023-2024 | Vectorisation ONNX |
| **Base Vectorielle** | LanceDB | 2023 | Stockage hybride (FTS + Vector) |
| **Cache** | GPTCache | 2023 | Acc√©l√©ration requ√™tes |
| **Query Expansion** | HyDE | 2022 | Am√©lioration requ√™tes |
| **Reranking** | MXBai Rerank v2 | 2024 | Affinage r√©sultats |
| **LLM** | Qwen3-4B (GGUF Q4) | 2025 | G√©n√©ration r√©ponses |
| **√âvaluation** | RAGAS | 2023 | M√©triques qualit√© |
| **Interface** | Streamlit | 2019 | UI interactive |

### D√©pendances Principales

```
docling>=2.0.0
trafilatura>=1.12.0
ftfy>=6.2.0
spacy>=3.7.0
fastembed>=0.3.0
lancedb>=0.13.0
gptcache>=0.1.43
llama-cpp-python>=0.2.0
ragas>=0.1.0
streamlit>=1.35.0
```

---

## ü§ù Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. Cr√©ez une branche (`git checkout -b feature/amelioration`)
3. Committez vos changements (`git commit -m 'Ajout fonctionnalit√©'`)
4. Pushez vers la branche (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

---

## üìÑ License

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

---

## üìû Contact

Pour toute question ou suggestion, n'h√©sitez pas √† ouvrir une [issue](https://github.com/user257814938/VEV_RAG/issues).

---

<div align="center">

**Fait avec ‚ù§Ô∏è pour la communaut√© IA locale**

‚≠ê Si ce projet vous est utile, n'h√©sitez pas √† lui donner une √©toile !

</div>
